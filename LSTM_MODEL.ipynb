{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getting original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nifty_50_data.csv\",index_col='Date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-03</th>\n",
       "      <td>4675.799805</td>\n",
       "      <td>4773.100098</td>\n",
       "      <td>4675.799805</td>\n",
       "      <td>4765.299805</td>\n",
       "      <td>4765.299805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>4774.950195</td>\n",
       "      <td>4782.850098</td>\n",
       "      <td>4728.850098</td>\n",
       "      <td>4749.649902</td>\n",
       "      <td>4749.649902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>4749.000000</td>\n",
       "      <td>4779.799805</td>\n",
       "      <td>4730.149902</td>\n",
       "      <td>4749.950195</td>\n",
       "      <td>4749.950195</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-06</th>\n",
       "      <td>4724.149902</td>\n",
       "      <td>4794.899902</td>\n",
       "      <td>4686.850098</td>\n",
       "      <td>4754.100098</td>\n",
       "      <td>4754.100098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-09</th>\n",
       "      <td>4747.549805</td>\n",
       "      <td>4758.700195</td>\n",
       "      <td>4695.450195</td>\n",
       "      <td>4742.799805</td>\n",
       "      <td>4742.799805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2012-01-03  4675.799805  4773.100098  4675.799805  4765.299805  4765.299805   \n",
       "2012-01-04  4774.950195  4782.850098  4728.850098  4749.649902  4749.649902   \n",
       "2012-01-05  4749.000000  4779.799805  4730.149902  4749.950195  4749.950195   \n",
       "2012-01-06  4724.149902  4794.899902  4686.850098  4754.100098  4754.100098   \n",
       "2012-01-09  4747.549805  4758.700195  4695.450195  4742.799805  4742.799805   \n",
       "\n",
       "            Volume  \n",
       "Date                \n",
       "2012-01-03       0  \n",
       "2012-01-04       0  \n",
       "2012-01-05       0  \n",
       "2012-01-06       0  \n",
       "2012-01-09       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "time_series_data = df['Close'].values.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform LSTM prediction\n",
    "def perform_LSTM(dataset, look_back, layer=5):\n",
    "    dataset = dataset.astype('float32')\n",
    "    dataset = np.reshape(dataset, (-1, 1))\n",
    "    \n",
    "    # # Normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    dataset = scaler.fit_transform(dataset)\n",
    "    \n",
    "    # Split data into training and testing set\n",
    "    train_size = int(len(dataset) * 0.9)\n",
    "    test_size = len(dataset) - train_size\n",
    "    train, test = dataset[0:train_size, :], dataset[train_size:, :]\n",
    "    \n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "    \n",
    "    print(trainX.shape)\n",
    "    print(trainY.shape)\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "    \n",
    "\n",
    "    # Create and fit the LSTM network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(layer, input_shape=(1, look_back)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=4, verbose=1)\n",
    "\n",
    "    # Make predictions\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "\n",
    "    # Invert predictions\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform([trainY])\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform([testY])\n",
    "    testing_error = np.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "\n",
    "    return testPredict, testY, testing_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 10\n",
    "\n",
    "# Perform LSTM prediction\n",
    "predicted_series, original_series,testing_error = perform_LSTM(time_series_data, look_back)\n",
    "\n",
    "# Print the testing error\n",
    "print(\"Testing RMSE:\", testing_error)\n",
    "\n",
    "# Plot original vs. predicted series\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(original_series.flatten(), label='Original Series')\n",
    "plt.plot(predicted_series.flatten(), label='Predicted Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Original vs. Predicted Series')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Perform LSTM prediction\n",
    "predicted_series, original_series, testing_error = perform_LSTM(time_series_data, look_back)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(original_series, predicted_series))\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(original_series, predicted_series)\n",
    "\n",
    "# Print RMSE and MAE\n",
    "print(\"Testing RMSE:\", rmse)\n",
    "print(\"Testing MAE:\", mae)\n",
    "\n",
    "# Plot original vs. predicted series\n",
    "plt.plot(original_series.flatten(), label='Original Series')\n",
    "plt.plot(predicted_series.flatten(), label='Predicted Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Original vs. Predicted Series')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model 2\n",
    "def perform_LSTM(dataset, look_back, layer=10, optimizer='adam', learning_rate=0.001, batch_size=4):\n",
    "    dataset = dataset.astype('float32')\n",
    "    dataset = np.reshape(dataset, (-1, 1))\n",
    "    \n",
    "    # # Normalize the data\n",
    "    # scaler = MinMaxScaler()\n",
    "    # dataset = scaler.fit_transform(dataset)\n",
    "    \n",
    "    # Split data into training and testing set\n",
    "    train_size = int(len(dataset) * 0.9)\n",
    "    test_size = len(dataset) - train_size\n",
    "    train, test = dataset[0:train_size, :], dataset[train_size:, :]\n",
    "    \n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "    \n",
    "    # Create and fit the LSTM network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(layer, input_shape=(1, look_back)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    model.fit(trainX, trainY, epochs=100, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    # Make predictions\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "\n",
    "    # Invert predictions\n",
    "    # trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    # trainY = scaler.inverse_transform([trainY])\n",
    "    # testPredict = scaler.inverse_transform(testPredict)\n",
    "    # testY = scaler.inverse_transform([testY])\n",
    "    testing_error = np.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "\n",
    "    return testPredict, testY, testing_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 10\n",
    "\n",
    "# Perform LSTM prediction\n",
    "predicted_series, original_series,testing_error = perform_LSTM(time_series_data, look_back)\n",
    "\n",
    "# Print the testing error\n",
    "print(\"Testing RMSE:\", testing_error)\n",
    "\n",
    "# Plot original vs. predicted series\n",
    "# Set the background color\n",
    "plt.figure(facecolor='lightgrey')\n",
    "\n",
    "# Plot original and predicted series\n",
    "plt.plot(original_series.flatten(), label='Original Series')\n",
    "plt.plot(predicted_series.flatten(), label='Predicted Series')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Closing price')\n",
    "plt.title('Original vs. Predicted Series')\n",
    "\n",
    "# Add grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single layer LSTM Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam, Adadelta, Nadam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Check if GPU is available\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found. Please ensure TensorFlow is configured with GPU support.\")\n",
    "\n",
    "# Function to create dataset\n",
    "def create_dataset(dataset, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# Function to perform LSTM prediction\n",
    "def perform_LSTM(dataset, look_back, neurons, optimizer, learning_rate, batch_size, num_executions=10):\n",
    "    dataset = dataset.astype('float32')\n",
    "    dataset = np.reshape(dataset, (-1, 1))\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "    # Split data into training and testing set\n",
    "    train_size = int(len(dataset) * 0.8)\n",
    "    test_size = len(dataset) - train_size\n",
    "    train, test = dataset[0:train_size, :], dataset[train_size:, :]\n",
    "\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "    # Calculate the number of steps per epoch\n",
    "    steps_per_epoch = len(trainX) // batch_size\n",
    "\n",
    "    # Initialize lists to store RMSE scores\n",
    "    rmse_scores = []\n",
    "\n",
    "    # Loop over num_executions times\n",
    "    for _ in range(num_executions):\n",
    "        # Create and compile the LSTM model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons, input_shape=(1, look_back)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer(learning_rate))\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(trainX, trainY, epochs=50, batch_size=batch_size, verbose=0, steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "        # Make predictions\n",
    "        testPredict = model.predict(testX)\n",
    "\n",
    "        # Invert predictions\n",
    "        testPredict = scaler.inverse_transform(testPredict)\n",
    "        testY_inv = scaler.inverse_transform([testY])\n",
    "\n",
    "        # Calculate RMSE\n",
    "        testing_error_rmse = np.sqrt(mean_squared_error(testY_inv[0], testPredict[:, 0]))\n",
    "        rmse_scores.append(testing_error_rmse)\n",
    "\n",
    "    # Calculate average RMSE score\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "\n",
    "    return avg_rmse\n",
    "\n",
    "\n",
    "\n",
    "#dataset and loookback\n",
    "\n",
    "dataset = df['Close'].values.reshape(-1, 1)\n",
    "look_back = 10\n",
    "\n",
    "\n",
    "# Define the range of hyperparameters\n",
    "neurons_list = [10, 30, 50, 100, 150, 200]\n",
    "optimizer_list = [Adam, Adadelta, Nadam]\n",
    "learning_rate_list = [0.1, 0.01, 0.001]\n",
    "batch_size_list = [4, 8, 16]\n",
    "\n",
    "\n",
    "\n",
    "# Perform grid search for hyperparameters\n",
    "best_rmse = float('inf')\n",
    "best_hyperparameters = None\n",
    "\n",
    "for neurons in neurons_list:\n",
    "    for optimizer in optimizer_list:\n",
    "        for learning_rate in learning_rate_list:\n",
    "            for batch_size in batch_size_list:\n",
    "                avg_rmse = perform_LSTM(dataset, look_back, neurons, optimizer, learning_rate, batch_size)\n",
    "                print(f\"Neurons: {neurons}, Optimizer: {optimizer.__name__}, Learning Rate: {learning_rate}, Batch Size: {batch_size}, Average RMSE: {avg_rmse}\")\n",
    "                if avg_rmse < best_rmse:\n",
    "                    best_rmse = avg_rmse\n",
    "                    best_hyperparameters = (neurons, optimizer.__name__, learning_rate, batch_size)\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(\"Neurons:\", best_hyperparameters[0])\n",
    "print(\"Optimizer:\", best_hyperparameters[1])\n",
    "print(\"Learning Rate:\", best_hyperparameters[2])\n",
    "print(\"Batch Size:\", best_hyperparameters[3])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
